{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.core import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Sparsifier():\n",
    "    def __init__(self, granularity, method, criteria):\n",
    "        self.granularity = granularity\n",
    "        self.method = method\n",
    "        self.criteria = criteria\n",
    "        \n",
    "    def prune(self, model, sparsity):\n",
    "        \n",
    "        for k, m in enumerate(model.modules()):\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if self.criteria == 'l1':\n",
    "                    weight = self._l1_norm(m.weight)\n",
    "                elif self.criteria == 'taylor':\n",
    "                    weight = self._taylor_crit(m.weight)\n",
    "                else: raise NameError('Invalid Criteria')\n",
    "                \n",
    "                mask = self._compute_mask(model, weight, sparsity)\n",
    "                print(mask.shape)\n",
    "                print(m.weight.shape)\n",
    "                mask = make_broadcastable(mask, m.weight)\n",
    "                m.register_buffer(\"_mask\", mask) # Put the mask into a buffer\n",
    "                self._apply(m)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def _apply(self, module):\n",
    "        '''\n",
    "        Apply the mask and freeze the gradient so the corresponding weights are not updated anymore\n",
    "        '''\n",
    "        mask = getattr(module, \"_mask\")\n",
    "        module.weight.data.mul_(mask)\n",
    "        if module.weight.grad is not None: # In case some layers are freezed\n",
    "            module.weight.grad.mul_(mask)\n",
    "\n",
    "        if self.granularity == 'filter': # If we remove complete filters, we want to remove the bias as well\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.mul_(mask.squeeze())\n",
    "                if module.bias.grad is not None: # In case some layers are freezed\n",
    "                    module.bias.grad.mul_(mask.squeeze())\n",
    "    \n",
    "    def _l1_norm(self, weight):\n",
    "\n",
    "        if self.granularity == 'weight':\n",
    "            w = weight.view(-1).abs().clone()\n",
    "            \n",
    "        elif self.granularity == 'vector':\n",
    "            w = torch.norm(weight, p=1, dim=(3)).view(-1)/(weight.shape[3])\n",
    "\n",
    "        elif self.granularity == 'kernel':\n",
    "            w = torch.norm(weight, p=1, dim=(2,3)).view(-1)/(weight.shape[2]*weight.shape[3])\n",
    "        \n",
    "        elif self.granularity == 'filter':\n",
    "            w = torch.norm(weight, p=1, dim=(1,2,3))/(weight.shape[1]*weight.shape[2]*weight.shape[3])\n",
    "\n",
    "        else: raise NameError('Invalid Granularity') \n",
    "        \n",
    "        return w\n",
    "        \n",
    "    def _taylor_crit(self, weight):\n",
    "        if weight.grad is not None:\n",
    "            if self.granularity == 'weight':\n",
    "                w = (weight*weight.grad).data.pow(2).view(-1)\n",
    "\n",
    "            elif self.granularity == 'vector':\n",
    "                w = (weight*weight.grad).data.pow(2).sum(dim=(3)).view(-1).clone()\n",
    "\n",
    "            elif self.granularity == 'kernel':\n",
    "                w = (weight*weight.grad).data.pow(2).sum(dim=(2,3)).view(-1).clone()     \n",
    "                \n",
    "            elif self.granularity == 'filter':       \n",
    "                w = (weight*weight.grad).data.pow(2).sum(dim=(1,2,3))\n",
    "\n",
    "            else: raise NameError('Invalid Granularity') \n",
    "\n",
    "            return w\n",
    "\n",
    "    \n",
    "    def _compute_mask(self, model, weight, sparsity):\n",
    "        '''\n",
    "        Compute the binary masks\n",
    "        '''\n",
    "        if self.method == 'global':\n",
    "            global_weight = []\n",
    "            \n",
    "            for k, m in enumerate(model.modules()):\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    if self.criteria == 'l1':\n",
    "                        w = self._l1_norm(m.weight)\n",
    "                    elif self.criteria == 'taylor':\n",
    "                        w = self._taylor_crit(m.weight)\n",
    "                        \n",
    "                    global_weight.append(w)\n",
    "\n",
    "            global_weight = torch.cat(global_weight)\n",
    "            threshold = torch.quantile(global_weight, sparsity/100) # Compute the threshold globally\n",
    "            \n",
    "        elif self.method == 'local': \n",
    "            threshold = torch.quantile(weight, sparsity/100)\n",
    "            \n",
    "        else: raise NameError('Invalid Method')\n",
    "            \n",
    "        # Make sure we don't remove every weight of a given layer\n",
    "        if threshold > weight.max(): threshold = weight.max()\n",
    "\n",
    "        mask = weight.ge(threshold).to(dtype=weight.dtype)\n",
    "\n",
    "        return mask\n",
    "        \n",
    "\n",
    "class SparsifyCallback(LearnerCallback):\n",
    "        \n",
    "    def __init__(self, learn:Learner, sparsity, granularity, method, criteria, sched_func):\n",
    "        super().__init__(learn)\n",
    "        self.sparsity, self.granularity, self.method, self.criteria, self.sched_func = sparsity, granularity, method, criteria, sched_func\n",
    "        self.sparsifier = Sparsifier(self.granularity, self.method, self.criteria)\n",
    "        self.batches = math.floor(len(learn.data.train_ds)/learn.data.train_dl.batch_size)\n",
    "    \n",
    "    def on_train_begin(self, n_epochs:int, **kwargs):\n",
    "        print(f'Pruning of {self.granularity} until a sparsity of {self.sparsity}%')\n",
    "        self.total_iters = n_epochs * self.batches\n",
    "        \n",
    "    def on_epoch_end(self, epoch, **kwargs):\n",
    "        print(f'Sparsity at epoch {epoch}: {self.current_sparsity:.2f}%')\n",
    "        \n",
    "    def on_batch_begin(self,iteration, **kwargs):\n",
    "        self.set_sparsity(iteration)\n",
    "        \n",
    "    def on_step_end(self, iteration, **kwargs):\n",
    "        self.sparsifier.prune(self.learn.model, self.current_sparsity)\n",
    "        \n",
    "    def set_sparsity(self, iteration):\n",
    "        self.current_sparsity = self.sched_func(start=0.0001, end=self.sparsity, pct=(iteration+1)/self.total_iters)\n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        print(f'Final Sparsity: {self.current_sparsity:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastai.core import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "def make_broadcastable(input, target):\n",
    "    target_shape = target.shape\n",
    "    output_shape = [*target.shape]\n",
    "    \n",
    "    for i in range(len(target_shape)):\n",
    "        input_size = np.prod(input.shape)\n",
    "        target_size = np.prod(np.array(target_shape[:i+1]))\n",
    "        if input_size >= target_size:\n",
    "            output_shape[i]=target_shape[i]\n",
    "        else:\n",
    "            output_shape[i]=1\n",
    "        \n",
    "    new_input = input.reshape(*output_shape)        \n",
    "    return new_input\n",
    "\n",
    "def annealing_gradual(start:Number, end:Number, pct:float)->Number:\n",
    "    \"Gradually anneal from `start` to `end` as pct goes from 0.0 to 1.0.\"\n",
    "    return end + start - end * (1 - pct)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGENETTE_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = (ImageList.from_folder(path)\n",
    "                .split_by_folder(train='train', valid='val')\n",
    "                .label_from_folder()\n",
    "                .transform(get_transforms(), size=64)\n",
    "                .databunch(bs=64)\n",
    "                .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/space/storage/homes/nathan/Code/fasterai\n"
     ]
    }
   ],
   "source": [
    "cd fasterai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterai.sparsifier_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterai.distillation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn = Learner(data, models.resnet18(), metrics=[accuracy])\n",
    "learn.fit_one_cycle(3, 1e-3)\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_1 = Learner(data, models.resnet18(), metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune = SparsifyCallback(learn_1, sparsity=10, granularity='weight', method='local', criteria='l1', sched_func=annealing_linear, lth_reset=True)\n",
    "KD = KnowledgeDistillation(learn_1, teacher=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pruning of weight until a sparsity of 10%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving Weights at epoch 0\n",
      "Sparsity at the end of epoch 0: 3.33%\n",
      "Sparsity at the end of epoch 1: 6.67%\n",
      "Sparsity at the end of epoch 2: 10.00%\n",
      "Final Sparsity: 10.00\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn_1.fit_one_cycle(3, 1e-3, callbacks=[prune, KD])\n",
    "learn_1.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_1 = Learner(data, models.resnet18(), metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune = SparsifyCallback(learn_1, sparsity=10, granularity='weight', method='local', criteria='l1', sched_func=annealing_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pruning of weight until a sparsity of 10%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving Weights at epoch 0\n",
      "Sparsity at the end of epoch 0: 3.33%\n",
      "Sparsity at the end of epoch 1: 6.67%\n",
      "Sparsity at the end of epoch 2: 10.00%\n",
      "Final Sparsity: 10.00\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn_1.fit_one_cycle(3, 1e-3, callbacks=[prune])\n",
    "learn_1.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_teacher = Learner(data, models.resnet18(pretrained=True), metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.375059</td>\n      <td>0.860187</td>\n      <td>0.749809</td>\n      <td>00:07</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.650054</td>\n      <td>0.497418</td>\n      <td>0.841783</td>\n      <td>00:08</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.386505</td>\n      <td>0.392868</td>\n      <td>0.875414</td>\n      <td>00:08</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn_teacher.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "KD = KnowledgeDistillation(learn_st, teacher=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.899284</td>\n      <td>0.897972</td>\n      <td>0.712357</td>\n      <td>00:09</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.874880</td>\n      <td>0.866431</td>\n      <td>0.717707</td>\n      <td>00:09</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.829745</td>\n      <td>0.840928</td>\n      <td>0.726369</td>\n      <td>00:10</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn_st.fit_one_cycle(3, 1e-4, callbacks=[KD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn_st.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pruning of weight until a sparsity of 50%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([9408])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([73728])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([8192])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([294912])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([32768])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1179648])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([131072])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([9408])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([73728])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([8192])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([294912])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([32768])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1179648])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([131072])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([9408])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([73728])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([8192])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([294912])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([32768])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1179648])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([131072])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([9408])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([73728])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([8192])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([294912])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([32768])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1179648])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([131072])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([9408])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([73728])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([8192])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([294912])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([32768])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1179648])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([131072])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([9408])\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([36864])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([73728])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([8192])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([147456])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([294912])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([32768])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([589824])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1179648])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([2359296])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "Final Sparsity: 0.02\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cf4e4e6f48a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSparsifyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'global'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msched_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannealing_cos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mon_step_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m\"Handle end of optimization step.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skip_zero'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, cb_name, call_mets, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcall_mets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_dl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/storage/homes/nathan/DEV/lib/python3.6/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36m_call_and_update\u001b[0;34m(self, cb, cb_name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_and_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;34m\"Call `cb_name` on `cb` and update the inner state.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'on_{cb_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8c5efb3518c5>\u001b[0m in \u001b[0;36mon_step_end\u001b[0;34m(self, iteration, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#self.set_sparsity(iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparsifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_sparsity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_sparsity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8c5efb3518c5>\u001b[0m in \u001b[0;36mprune\u001b[0;34m(self, model, sparsity)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid Criteria'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8c5efb3518c5>\u001b[0m in \u001b[0;36m_compute_mask\u001b[0;34m(self, model, weight, sparsity)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mglobal_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Compute the threshold globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'local'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-3, callbacks=[SparsifyCallback(learn, sparsity=50, granularity='weight', method='global', criteria='l1', sched_func=annealing_cos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.6817698, tensor(0.4283)]"
      ]
     },
     "metadata": {},
     "execution_count": 439
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2.055264, tensor(0.2713)]"
      ]
     },
     "metadata": {},
     "execution_count": 450
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "source": [
    "## KD Pruning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparsifyCallback(LearnerCallback):\n",
    "        \n",
    "    def __init__(self, learn:Learner, sparsity, granularity, method, criteria, sched_func, start_epoch=0, lth_reset=False, rewind_epoch=0, reset_end=False):\n",
    "        super().__init__(learn)\n",
    "        self.sparsity, self.granularity, self.method, self.criteria, self.sched_func = sparsity, granularity, method, criteria, sched_func\n",
    "        self.reset_end, self.rewind_epoch, self.start_epoch, self.lth_reset = reset_end, rewind_epoch, start_epoch, lth_reset\n",
    "        self.sparsifier = Sparsifier(self.learn.model, self.granularity, self.method, self.criteria)\n",
    "        self.batches = math.floor(len(learn.data.train_ds)/learn.data.train_dl.batch_size)\n",
    "        self.current_sparsity, self.previous_sparsity = 0,0\n",
    "        self.T, self.α = 20, 0.7\n",
    "\n",
    "        assert self.start_epoch>=self.rewind_epoch, 'You must rewind to an epoch before the start of the pruning process'\n",
    "    \n",
    "    def on_train_begin(self, n_epochs:int, **kwargs):\n",
    "        print(f'Pruning of {self.granularity} until a sparsity of {self.sparsity}%')\n",
    "        self.total_iters = n_epochs * self.batches\n",
    "        self.start_iter = self.start_epoch * self.batches\n",
    "        \n",
    "    def on_epoch_end(self, epoch, **kwargs):\n",
    "        print(f'Sparsity at the end of epoch {epoch}: {self.current_sparsity:.2f}%')\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        if epoch == self.rewind_epoch:\n",
    "            print(f'Saving Weights at epoch {epoch}')\n",
    "            self.sparsifier._save_weights()\n",
    "        \n",
    "    def on_batch_begin(self, iteration, epoch, **kwargs):\n",
    "        if epoch>=self.start_epoch:\n",
    "            self.set_sparsity(iteration)\n",
    "            self.teacher = self.learn.deepcopy()\n",
    "            self.sparsifier.prune(self.current_sparsity)\n",
    "             \n",
    "\n",
    "            if self.lth_reset and self.current_sparsity!=self.previous_sparsity: # If sparsity has changed, the network has been pruned\n",
    "                    print(f'Resetting Weights to their epoch {self.rewind_epoch} values')\n",
    "                    self.sparsifier._reset_weights()\n",
    "\n",
    "        self.previous_sparsity = self.current_sparsity\n",
    "        \n",
    "    def set_sparsity(self, iteration):\n",
    "        self.current_sparsity = self.sched_func(start=0., end=self.sparsity, pct=(iteration-self.start_iter)/(self.total_iters-self.start_iter))\n",
    "        \n",
    "    def on_backward_begin(self, last_input, last_output, last_target, **kwargs):\n",
    "        self.teacher.model.eval()\n",
    "        teacher_output = self.teacher.model(last_input)\n",
    "        new_loss = DistillationLoss(last_output, last_target, teacher_output, self.T, self.α)\n",
    "        \n",
    "        return {'last_loss': new_loss}\n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        print(f'Final Sparsity: {self.current_sparsity:.2f}')\n",
    "        if self.reset_end:\n",
    "            self.sparsifier._reset_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistillationLoss(y, labels, teacher_scores, T, alpha):\n",
    "    return nn.KLDivLoss(reduction='batchmean')(F.log_softmax(y/T, dim=-1), F.softmax(teacher_scores/T, dim=-1)) * (T*T * 2.0 * alpha) + F.cross_entropy(y, labels) * (1. - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, learn:Learner, teacher:Learner, T:float=20., α:float=0.7):\n",
    "        super().__init__(learn)\n",
    "        self.teacher = teacher\n",
    "        self.T, self.α = T, α\n",
    "    \n",
    "    def on_backward_begin(self, last_input, last_output, last_target, **kwargs):\n",
    "        self.teacher.model.eval()\n",
    "        teacher_output = self.teacher.model(last_input)\n",
    "        new_loss = DistillationLoss(last_output, last_target, teacher_output, self.T, self.α)\n",
    "        \n",
    "        return {'last_loss': new_loss}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity in Conv2d 1: 96.88%\nSparsity in Conv2d 7: 0.00%\nSparsity in Conv2d 10: 0.00%\nSparsity in Conv2d 13: 0.00%\nSparsity in Conv2d 16: 0.00%\nSparsity in Conv2d 20: 0.00%\nSparsity in Conv2d 23: 0.00%\nSparsity in Conv2d 26: 0.00%\nSparsity in Conv2d 29: 0.00%\nSparsity in Conv2d 32: 0.00%\nSparsity in Conv2d 36: 32.03%\nSparsity in Conv2d 39: 24.61%\nSparsity in Conv2d 42: 0.00%\nSparsity in Conv2d 45: 30.08%\nSparsity in Conv2d 48: 26.56%\nSparsity in Conv2d 52: 99.80%\nSparsity in Conv2d 55: 99.80%\nSparsity in Conv2d 58: 0.00%\nSparsity in Conv2d 61: 99.80%\nSparsity in Conv2d 64: 99.80%\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(learn.model.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(f\"Sparsity in {m.__class__.__name__} {k}: {100. * float(torch.sum(m.weight == 0))/ float(m.weight.nelement()):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sparsity in Conv2d 1: 98.44%\nSparsity in Conv2d 7: 98.44%\nSparsity in Conv2d 10: 98.44%\nSparsity in Conv2d 13: 98.44%\nSparsity in Conv2d 16: 98.44%\nSparsity in Conv2d 20: 99.22%\nSparsity in Conv2d 23: 96.88%\nSparsity in Conv2d 26: 99.22%\nSparsity in Conv2d 29: 95.31%\nSparsity in Conv2d 32: 96.09%\nSparsity in Conv2d 36: 99.61%\nSparsity in Conv2d 39: 0.00%\nSparsity in Conv2d 42: 99.61%\nSparsity in Conv2d 45: 0.00%\nSparsity in Conv2d 48: 0.00%\nSparsity in Conv2d 52: 84.18%\nSparsity in Conv2d 55: 0.00%\nSparsity in Conv2d 58: 99.80%\nSparsity in Conv2d 61: 0.00%\nSparsity in Conv2d 64: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(learn.model.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(f\"Sparsity in {m.__class__.__name__} {k}: {100. * float(torch.sum(m.weight == 0))/ float(m.weight.nelement()):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(10,100,3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([172.6954, 171.7417, 173.2661, 173.3760, 173.9668, 173.8984, 173.0813,\n",
       "        173.5202, 173.2958, 172.3175])"
      ]
     },
     "metadata": {},
     "execution_count": 457
    }
   ],
   "source": [
    "torch.norm(a, p=2, dim=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([29823.7070, 29495.2441, 30021.1211, 30059.1621, 30264.4707, 30240.7129,\n",
       "        29957.1465, 30109.3848, 30031.4355, 29693.3477])"
      ]
     },
     "metadata": {},
     "execution_count": 459
    }
   ],
   "source": [
    "(a).data.pow(2).sum(dim=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3000])"
      ]
     },
     "metadata": {},
     "execution_count": 417
    }
   ],
   "source": [
    "#(torch.norm(a, p=1, dim=(3))/(a.shape[3])).shape\n",
    "(a.abs().sum(dim=(3)).view(-1).clone()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.8004, 0.8037, 0.7933, 0.8009, 0.7991, 0.7969, 0.7933, 0.8015, 0.7884,\n",
       "        0.7880])"
      ]
     },
     "metadata": {},
     "execution_count": 353
    }
   ],
   "source": [
    "torch.norm(a, p=1, dim=(1,2,3))/(a.shape[1]*a.shape[2]*a.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 11, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 344
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12100"
      ]
     },
     "metadata": {},
     "execution_count": 345
    }
   ],
   "source": [
    "torch.numel(a[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.8076)"
      ]
     },
     "metadata": {},
     "execution_count": 268
    }
   ],
   "source": [
    "(a.abs().sum(dim=(3)).view(-1)/a.shape[3]).mean()\n",
    "\n",
    "#/(a.shape[2]*a.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.granularity == 'weight':\n",
    "            w = weight.view(-1).abs().clone()\n",
    "            \n",
    "        elif self.granularity == 'vector':\n",
    "            w = weight.abs().sum(dim=(3)).view(-1).clone()/(weight.shape[2]*weight.shape[3])\n",
    "            #w = weight.abs().sum(dim=(3)).view(-1).clone()\n",
    "\n",
    "        elif self.granularity == 'kernel':\n",
    "            w = weight.abs().sum(dim=(2,3)).view(-1).clone()/weight.shape[2]  \n",
    "        \n",
    "        elif self.granularity == 'filter':\n",
    "            w = weight.abs().sum(dim=(1,2,3)).clone()/weight.shape[1]"
   ]
  }
 ]
}